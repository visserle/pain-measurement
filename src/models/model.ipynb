{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%capture\n",
                "from pathlib import Path\n",
                "\n",
                "if Path.cwd().stem == \"models\":\n",
                "    %cd ../..\n",
                "    %load_ext autoreload\n",
                "    %autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "18:29:17 | \u001b[92mINFO    \u001b[0m| utils | Using device: mps\n"
                    ]
                }
            ],
            "source": [
                "import logging\n",
                "import operator\n",
                "from functools import reduce\n",
                "from pathlib import Path\n",
                "\n",
                "import holoviews as hv\n",
                "import hvplot.polars  # noqa\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import optuna\n",
                "import polars as pl\n",
                "import seaborn as sns\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from icecream import ic\n",
                "from ipywidgets import interact\n",
                "from polars import col\n",
                "from polars.datatypes.group import FLOAT_DTYPES, INTEGER_DTYPES\n",
                "from sklearn.metrics import auc, confusion_matrix, roc_curve\n",
                "from sklearn.model_selection import GroupShuffleSplit\n",
                "from torch.utils.data import DataLoader, TensorDataset\n",
                "\n",
                "from src.data.database_manager import DatabaseManager\n",
                "from src.features.labels import add_labels\n",
                "from src.features.resampling import (\n",
                "    add_normalized_timestamp,\n",
                "    interpolate_and_fill_nulls,\n",
                "    resample_at_10_hz_equidistant,\n",
                ")\n",
                "from src.features.scaling import scale_min_max, scale_robust_standard, scale_standard\n",
                "from src.features.transforming import merge_dfs\n",
                "from src.features.utils import to_describe\n",
                "from src.log_config import configure_logging\n",
                "from src.models.architectures import LongShortTermMemory, MultiLayerPerceptron\n",
                "from src.models.data_loader import create_dataloaders, transform_sample_df_to_arrays\n",
                "from src.models.sample_creation import create_samples, make_sample_set_balanced\n",
                "from src.models.scalers import StandardScaler3D, scale_dataset\n",
                "from src.models.utils import get_device, load_model, save_model, get_input_shape\n",
                "from src.plots.utils import prepare_multiline_hvplot\n",
                "\n",
                "configure_logging(\n",
                "    stream_level=logging.DEBUG,\n",
                "    ignore_libs=[\"matplotlib\", \"Comm\", \"bokeh\", \"tornado\"],\n",
                ")\n",
                "\n",
                "pl.Config.set_tbl_rows(12)  # for the 12 trials\n",
                "hv.output(widget_location=\"bottom\", size=130)\n",
                "\n",
                "device = get_device()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.models.models_optuna_tsl import initialize_model\n",
                "\n",
                "logger = logging.getLogger(__name__.rsplit(\".\", 1)[-1])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "18:29:17 | \u001b[92mINFO    \u001b[0m| utils | Using device: mps\n",
                        "18:29:17 | \u001b[92mINFO    \u001b[0m| utils | Loaded PatchTST model (input_shape=(51, 3)) with test accuracy 0.79%\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/visser/Dropbox/PhD/Code/pain-measurement/src/models/utils.py:106: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
                        "  save_dict = torch.load(model_path)\n"
                    ]
                }
            ],
            "source": [
                "model = load_model(\"models/PatchTST_20250310-174850.pt\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/var/folders/54/0yy_ylvj7tx247wkq0n07dnr0000gn/T/ipykernel_36662/1829709086.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
                        "  save_dict = torch.load(model_path, map_location=device)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading model PatchTST with test accuracy: 0.7854785478547854\n"
                    ]
                },
                {
                    "ename": "AttributeError",
                    "evalue": "'NoneType' object has no attribute 'shape'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[38], line 175\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    174\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/PatchTST_20250310-174850.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your model path\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
                        "Cell \u001b[0;32mIn[38], line 106\u001b[0m, in \u001b[0;36mevaluate_saved_model\u001b[0;34m(model_path, dataset_params)\u001b[0m\n\u001b[1;32m    103\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Create test dataloader\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m _, test_loader \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataloaders\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[1;32m    111\u001b[0m y_true \u001b[38;5;241m=\u001b[39m []\n",
                        "File \u001b[0;32m~/Dropbox/PhD/Code/pain-measurement/src/models/data_loader.py:96\u001b[0m, in \u001b[0;36mcreate_dataloaders\u001b[0;34m(X_train, y_train, X_test, y_test, batch_size, is_test)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_dataloaders\u001b[39m(\n\u001b[1;32m     88\u001b[0m     X_train: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[1;32m     89\u001b[0m     y_train: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[DataLoader, DataLoader]:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# Sanity check\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_test\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m, (\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_train and X_test must have 3 dimensions: (samples, timesteps, features)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m     )\n\u001b[1;32m    100\u001b[0m     train_data \u001b[38;5;241m=\u001b[39m TensorDataset(\n\u001b[1;32m    101\u001b[0m         torch\u001b[38;5;241m.\u001b[39mFloatTensor(X_train),\n\u001b[1;32m    102\u001b[0m         torch\u001b[38;5;241m.\u001b[39mFloatTensor(y_train),\n\u001b[1;32m    103\u001b[0m     )\n\u001b[1;32m    104\u001b[0m     test_data \u001b[38;5;241m=\u001b[39m TensorDataset(\n\u001b[1;32m    105\u001b[0m         torch\u001b[38;5;241m.\u001b[39mFloatTensor(X_test),\n\u001b[1;32m    106\u001b[0m         torch\u001b[38;5;241m.\u001b[39mFloatTensor(y_test),\n\u001b[1;32m    107\u001b[0m     )\n",
                        "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
                    ]
                }
            ],
            "source": [
                "RANDOM_SEED = 42\n",
                "BATCH_SIZE = 64\n",
                "\n",
                "\n",
                "def evaluate_saved_model(model_path, dataset_params=None):\n",
                "    \"\"\"\n",
                "    Load a saved model and evaluate it on the test set to generate a confusion matrix.\n",
                "\n",
                "    Args:\n",
                "        model_path: Path to the saved model file\n",
                "        dataset_params: Optional dictionary with custom dataset parameters.\n",
                "                       If None, uses the same parameters as in training.\n",
                "    \"\"\"\n",
                "    import matplotlib.pyplot as plt\n",
                "    import numpy as np\n",
                "    import torch\n",
                "    from sklearn.metrics import (\n",
                "        confusion_matrix,\n",
                "        ConfusionMatrixDisplay,\n",
                "        classification_report,\n",
                "    )\n",
                "\n",
                "    # Use default parameters if none provided\n",
                "    if dataset_params is None:\n",
                "        dataset_params = {\n",
                "            \"exclude_trials_with_measurement_problems\": True,\n",
                "            \"intervals\": {\n",
                "                \"decreases\": \"major_decreasing_intervals\",\n",
                "                \"increases\": \"strictly_increasing_intervals_without_plateaus\",\n",
                "            },\n",
                "            \"label_mapping\": {\n",
                "                \"decreases\": 0,\n",
                "                \"increases\": 1,\n",
                "            },\n",
                "            \"sample_duration_ms\": 5000,\n",
                "            \"feature_columns\": [\n",
                "                \"eda_tonic\",\n",
                "                \"eda_phasic\",\n",
                "                \"pupil_mean\",\n",
                "            ],\n",
                "        }\n",
                "\n",
                "    # Load model\n",
                "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "    save_dict = torch.load(model_path, map_location=device)\n",
                "    model_name = save_dict[\"model_name\"]\n",
                "    hyperparams = save_dict[\"hyperparameters\"]\n",
                "    state_dict = save_dict[\"model_state_dict\"]\n",
                "    input_shape = save_dict[\"input_shape\"]\n",
                "\n",
                "    print(\n",
                "        f\"Loading model {model_name} with test accuracy: {save_dict['test_accuracy']}\"\n",
                "    )\n",
                "\n",
                "    # Get data for evaluation\n",
                "    db = DatabaseManager()\n",
                "    with db:\n",
                "        df = db.get_table(\n",
                "            \"Merged_and_Labeled_Data\",\n",
                "            exclude_trials_with_measurement_problems=dataset_params[\n",
                "                \"exclude_trials_with_measurement_problems\"\n",
                "            ],\n",
                "        )\n",
                "\n",
                "    # Create and prepare dataset\n",
                "    samples = create_samples(\n",
                "        df,\n",
                "        dataset_params[\"intervals\"],\n",
                "        dataset_params[\"sample_duration_ms\"],\n",
                "        dataset_params[\"label_mapping\"],\n",
                "    )\n",
                "    samples = make_sample_set_balanced(samples)\n",
                "    samples = samples.select(\n",
                "        \"sample_id\",\n",
                "        \"participant_id\",\n",
                "        \"rating\",\n",
                "        \"temperature\",\n",
                "        \"eda_raw\",\n",
                "        \"eda_tonic\",\n",
                "        \"eda_phasic\",\n",
                "        \"pupil_mean\",\n",
                "        \"pupil_mean_tonic\",\n",
                "        \"label\",\n",
                "    )\n",
                "\n",
                "    X, y, groups = transform_sample_df_to_arrays(\n",
                "        samples, feature_columns=dataset_params[\"feature_columns\"]\n",
                "    )\n",
                "\n",
                "    # Split the data into training+validation set and test set\n",
                "    splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_SEED)\n",
                "    idx_train_val, idx_test = next(splitter.split(X, y, groups=groups))\n",
                "    X_test, y_test = X[idx_test], y[idx_test]\n",
                "\n",
                "    # Initialize model\n",
                "    model, criterion, _, _ = initialize_model(\n",
                "        model_name, input_shape, device, **hyperparams\n",
                "    )\n",
                "\n",
                "    # Load weights\n",
                "    model.load_state_dict(state_dict)\n",
                "    model.to(device)\n",
                "    model.eval()\n",
                "\n",
                "    # Create test dataloader\n",
                "    _, test_loader = create_dataloaders(\n",
                "        None, None, X_test, y_test, batch_size=BATCH_SIZE\n",
                "    )\n",
                "\n",
                "    # Evaluate model\n",
                "    y_true = []\n",
                "    y_pred = []\n",
                "\n",
                "    with torch.no_grad():\n",
                "        for inputs, targets in test_loader:\n",
                "            inputs = inputs.to(device)\n",
                "            outputs = model(inputs)\n",
                "            _, predicted = torch.max(outputs, 1)\n",
                "\n",
                "            y_true.extend(targets.cpu().numpy())\n",
                "            y_pred.extend(predicted.cpu().numpy())\n",
                "\n",
                "    # Calculate confusion matrix\n",
                "    cm = confusion_matrix(y_true, y_pred)\n",
                "\n",
                "    # Display confusion matrix\n",
                "    class_names = list(dataset_params[\"label_mapping\"].keys())\n",
                "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
                "    fig, ax = plt.subplots(figsize=(10, 8))\n",
                "    disp.plot(ax=ax)\n",
                "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
                "    plt.savefig(f\"confusion_matrix_{model_name}.png\")\n",
                "    plt.show()\n",
                "\n",
                "    # Print classification report\n",
                "    print(\"\\nClassification Report:\")\n",
                "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
                "\n",
                "    return {\n",
                "        \"confusion_matrix\": cm,\n",
                "        \"classification_report\": classification_report(\n",
                "            y_true, y_pred, target_names=class_names, output_dict=True\n",
                "        ),\n",
                "        \"y_true\": y_true,\n",
                "        \"y_pred\": y_pred,\n",
                "    }\n",
                "\n",
                "\n",
                "# Helper function to save model\n",
                "def save_model(model, accuracy, best_params, model_name, X_sample):\n",
                "    \"\"\"Save model with all necessary information for later inference.\"\"\"\n",
                "    import os\n",
                "    import torch\n",
                "\n",
                "    # Create directory if it doesn't exist\n",
                "    os.makedirs(\"models\", exist_ok=True)\n",
                "\n",
                "    # Create save dictionary with all necessary information\n",
                "    save_dict = {\n",
                "        \"model_state_dict\": model.state_dict(),\n",
                "        \"hyperparameters\": best_params,\n",
                "        \"model_name\": model_name,\n",
                "        \"test_accuracy\": accuracy,\n",
                "        \"input_shape\": get_input_shape(model_name, X_sample),\n",
                "    }\n",
                "\n",
                "    # Save the model\n",
                "    torch.save(save_dict, f\"models/{model_name}.pt\")\n",
                "    print(f\"Model saved to models/{model_name}.pt\")\n",
                "\n",
                "\n",
                "# Usage example\n",
                "if __name__ == \"__main__\":\n",
                "    model_path = \"models/PatchTST_20250310-174850.pt\"  # Replace with your model path\n",
                "    results = evaluate_saved_model(model_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "device(type='cuda')"
                        ]
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "torch.device(\"cuda\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import accuracy_score\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "from src.models.inception_time_pytorch.model import InceptionTime\n",
                "from src.models.inception_time_pytorch.modules import InceptionModel\n",
                "from src.models.inception_time_pytorch.plots import plot\n",
                "\n",
                "# Generate the data\n",
                "N = 60  # number of time series\n",
                "C = 10  # number of dimensions of each time series\n",
                "L = 100  # number of samples of each time series\n",
                "# x = np.zeros((N, C, L))\n",
                "x = np.zeros((N, L, C))\n",
                "# t = np.linspace(0, 1, L)\n",
                "t = np.linspace(0, 1, C)\n",
                "c = np.cos(2 * np.pi * (10 * t - 0.5))\n",
                "s = np.sin(2 * np.pi * (20 * t - 0.5))\n",
                "x[: N // 3] = 20 + 20 * c + 5 * np.random.normal(size=(N // 3, L, C))\n",
                "x[N // 3 : 2 * N // 3] = 20 + 20 * s + 5 * np.random.normal(size=(N // 3, L, C))\n",
                "x[2 * N // 3 :] = 20 + 20 * c + 20 * s + 5 * np.random.normal(size=(N // 3, L, C))\n",
                "y = np.concatenate([0 * np.ones(N // 3), 1 * np.ones(N // 3), 2 * np.ones(N // 3)])\n",
                "\n",
                "\n",
                "# Scale the data.\n",
                "mu = np.nanmean(x, axis=0, keepdims=True)\n",
                "sigma = np.nanstd(x, axis=0, keepdims=True)\n",
                "x = (x - mu) / sigma\n",
                "\n",
                "# Save the data.\n",
                "x = torch.from_numpy(x).float().to(device)\n",
                "y = torch.from_numpy(y).long().to(device)\n",
                "\n",
                "# custom data\n",
                "# y = torch.from_numpy(y_.copy()).long().to(device)\n",
                "# x = torch.from_numpy(X.transpose(0, 2, 1)).float().to(device)\n",
                "\n",
                "# Split the data\n",
                "# x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.3)\n",
                "\n",
                "\n",
                "# # Generate the training dataset.\n",
                "# dataset = torch.utils.data.DataLoader(\n",
                "#     dataset=torch.utils.data.TensorDataset(x, y),\n",
                "#     batch_size=32,\n",
                "#     shuffle=True,\n",
                "# )\n",
                "\n",
                "\n",
                "# # Create the model\n",
                "# model = InceptionModel(input_size=x.shape[1], num_classes=3, filters=32, depth=6).to(\n",
                "#     device\n",
                "# )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "torch.Size([60, 100, 10])"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "x.size()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Namespace = lambda x: x\n",
                "configs: Namespace(\n",
                "    task_name=\"classification\",\n",
                "    is_training=1,\n",
                "    model_id=\"UWaveGestureLibrary\",\n",
                "    model=\"PatchTST\",\n",
                "    data=\"UEA\",\n",
                "    root_path=\"./dataset/UWaveGestureLibrary/\",\n",
                "    data_path=\"ETTh1.csv\",\n",
                "    features=\"M\",\n",
                "    target=\"OT\",\n",
                "    freq=\"h\",\n",
                "    checkpoints=\"./checkpoints/\",\n",
                "    seq_len=np.int64(315),\n",
                "    label_len=48,\n",
                "    pred_len=0,\n",
                "    seasonal_patterns=\"Monthly\",\n",
                "    inverse=False,\n",
                "    mask_rate=0.25,\n",
                "    anomaly_ratio=0.25,\n",
                "    expand=2,\n",
                "    d_conv=4,\n",
                "    top_k=3,\n",
                "    num_kernels=6,\n",
                "    enc_in=3,\n",
                "    dec_in=7,\n",
                "    c_out=7,\n",
                "    d_model=128,\n",
                "    n_heads=8,\n",
                "    e_layers=3,\n",
                "    d_layers=1,\n",
                "    d_ff=256,\n",
                "    moving_avg=25,\n",
                "    factor=1,\n",
                "    distil=True,\n",
                "    dropout=0.1,\n",
                "    embed=\"timeF\",\n",
                "    activation=\"gelu\",\n",
                "    channel_independence=1,\n",
                "    decomp_method=\"moving_avg\",\n",
                "    use_norm=1,\n",
                "    down_sampling_layers=0,\n",
                "    down_sampling_window=1,\n",
                "    down_sampling_method=None,\n",
                "    seg_len=96,\n",
                "    num_workers=10,\n",
                "    itr=1,\n",
                "    train_epochs=100,\n",
                "    batch_size=16,\n",
                "    patience=10,\n",
                "    learning_rate=0.001,\n",
                "    des=\"Exp\",\n",
                "    loss=\"MSE\",\n",
                "    lradj=\"type1\",\n",
                "    use_amp=False,\n",
                "    use_gpu=True,\n",
                "    gpu=0,\n",
                "    gpu_type=\"cuda\",\n",
                "    use_multi_gpu=False,\n",
                "    devices=\"0,1,2,3\",\n",
                "    p_hidden_dims=[128, 128],\n",
                "    p_hidden_layers=2,\n",
                "    use_dtw=False,\n",
                "    augmentation_ratio=0,\n",
                "    seed=2,\n",
                "    jitter=False,\n",
                "    scaling=False,\n",
                "    permutation=False,\n",
                "    randompermutation=False,\n",
                "    magwarp=False,\n",
                "    timewarp=False,\n",
                "    windowslice=False,\n",
                "    windowwarp=False,\n",
                "    rotation=False,\n",
                "    spawner=False,\n",
                "    dtwwarp=False,\n",
                "    shapedtwwarp=False,\n",
                "    wdba=False,\n",
                "    discdtw=False,\n",
                "    discsdtw=False,\n",
                "    extra_tag=\"\",\n",
                "    patch_len=16,\n",
                "    device=device(type=\"mps\"),\n",
                "    num_class=8,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "\n",
                "from src.Time_Series_Library.layers.Embed import PatchEmbedding\n",
                "from src.Time_Series_Library.layers.SelfAttention_Family import (\n",
                "    AttentionLayer,\n",
                "    FullAttention,\n",
                ")\n",
                "from src.Time_Series_Library.layers.Transformer_EncDec import Encoder, EncoderLayer\n",
                "\n",
                "\n",
                "class Transpose(nn.Module):\n",
                "    def __init__(self, *dims, contiguous=False):\n",
                "        super().__init__()\n",
                "        self.dims, self.contiguous = dims, contiguous\n",
                "\n",
                "    def forward(self, x):\n",
                "        if self.contiguous:\n",
                "            return x.transpose(*self.dims).contiguous()\n",
                "        else:\n",
                "            return x.transpose(*self.dims)\n",
                "\n",
                "\n",
                "class Model(nn.Module):\n",
                "    \"\"\"\n",
                "    Paper link: https://arxiv.org/pdf/2211.14730.pdf\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        num_class,  # number of classes, adapt to dataset\n",
                "        seq_len=np.int64(315),\n",
                "        patch_len=16,\n",
                "        stride=8,\n",
                "        d_model=128,  # dimension of embedding\n",
                "        dropout=0.1,\n",
                "        factor=1,\n",
                "        activation=\"gelu\",\n",
                "        n_heads=8,\n",
                "        d_ff=256,\n",
                "        e_layers=3,\n",
                "        enc_in=3,  #  encoder input size, the number of features for a piece of data\n",
                "    ):\n",
                "        \"\"\"\n",
                "        patch_len: int, patch len for patch_embedding\n",
                "        stride: int, stride for patch_embedding\n",
                "        \"\"\"\n",
                "        super().__init__()\n",
                "        padding = stride\n",
                "\n",
                "        # patching and embedding\n",
                "        self.patch_embedding = PatchEmbedding(\n",
                "            d_model, patch_len, stride, padding, dropout\n",
                "        )\n",
                "\n",
                "        # Encoder\n",
                "        self.encoder = Encoder(\n",
                "            [\n",
                "                EncoderLayer(\n",
                "                    AttentionLayer(\n",
                "                        FullAttention(\n",
                "                            False,\n",
                "                            factor,\n",
                "                            attention_dropout=dropout,\n",
                "                            output_attention=False,\n",
                "                        ),\n",
                "                        d_model,\n",
                "                        n_heads,\n",
                "                    ),\n",
                "                    d_model,\n",
                "                    d_ff,\n",
                "                    dropout=dropout,\n",
                "                    activation=activation,\n",
                "                )\n",
                "                for _ in range(e_layers)\n",
                "            ],\n",
                "            norm_layer=nn.Sequential(\n",
                "                Transpose(1, 2),\n",
                "                nn.BatchNorm1d(d_model),\n",
                "                Transpose(1, 2),\n",
                "            ),\n",
                "        )\n",
                "\n",
                "        # Classification head\n",
                "        self.head_nf = d_model * int((seq_len - patch_len) / stride + 2)\n",
                "        self.flatten = nn.Flatten(start_dim=-2)\n",
                "        self.dropout = nn.Dropout(dropout)\n",
                "        self.projection = nn.Linear(self.head_nf * enc_in, num_class)\n",
                "\n",
                "    def forward(self, x_enc, x_mark_enc):\n",
                "        # Normalization from Non-stationary Transformer\n",
                "        means = x_enc.mean(1, keepdim=True).detach()\n",
                "        x_enc = x_enc - means\n",
                "        stdev = torch.sqrt(torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)\n",
                "        x_enc /= stdev\n",
                "\n",
                "        # do patching and embedding\n",
                "        x_enc = x_enc.permute(0, 2, 1)\n",
                "        # u: [bs * nvars x patch_num x d_model]\n",
                "        enc_out, n_vars = self.patch_embedding(x_enc)\n",
                "\n",
                "        # Encoder\n",
                "        # z: [bs * nvars x patch_num x d_model]\n",
                "        enc_out, attns = self.encoder(enc_out)\n",
                "        # z: [bs x nvars x patch_num x d_model]\n",
                "        enc_out = torch.reshape(\n",
                "            enc_out, (-1, n_vars, enc_out.shape[-2], enc_out.shape[-1])\n",
                "        )\n",
                "        # z: [bs x nvars x d_model x patch_num]\n",
                "        enc_out = enc_out.permute(0, 1, 3, 2)\n",
                "\n",
                "        # Decoder\n",
                "        output = self.flatten(enc_out)\n",
                "        output = self.dropout(output)\n",
                "        output = output.reshape(output.shape[0], -1)\n",
                "        output = self.projection(output)  # (batch_size, num_classes)\n",
                "        # output is dec_out: [B, N]\n",
                "        return output\n",
                "\n",
                "\n",
                "model = Model(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate the data\n",
                "N = 60  # number of time series\n",
                "C = 10  # number of dimensions of each time series\n",
                "L = 100  # number of samples of each time series\n",
                "# x = np.zeros((N, C, L))\n",
                "x = np.zeros((N, L, C))\n",
                "# t = np.linspace(0, 1, L)\n",
                "t = np.linspace(0, 1, C)\n",
                "c = np.cos(2 * np.pi * (10 * t - 0.5))\n",
                "s = np.sin(2 * np.pi * (20 * t - 0.5))\n",
                "x[: N // 3] = 20 + 20 * c + 5 * np.random.normal(size=(N // 3, L, C))\n",
                "x[N // 3 : 2 * N // 3] = 20 + 20 * s + 5 * np.random.normal(size=(N // 3, L, C))\n",
                "x[2 * N // 3 :] = 20 + 20 * c + 20 * s + 5 * np.random.normal(size=(N // 3, L, C))\n",
                "y = np.concatenate([0 * np.ones(N // 3), 1 * np.ones(N // 3), 2 * np.ones(N // 3)])\n",
                "\n",
                "\n",
                "# Scale the data.\n",
                "mu = np.nanmean(x, axis=0, keepdims=True)\n",
                "sigma = np.nanstd(x, axis=0, keepdims=True)\n",
                "x = (x - mu) / sigma\n",
                "\n",
                "# Save the data.\n",
                "x = torch.from_numpy(x).float().to(device)\n",
                "y = torch.from_numpy(y).long().to(device)\n",
                "\n",
                "# custom data\n",
                "# y = torch.from_numpy(y_.copy()).long().to(device)\n",
                "# x = torch.from_numpy(X.transpose(0, 2, 1)).float().to(device)\n",
                "\n",
                "# Split the data\n",
                "# x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.3)\n",
                "\n",
                "\n",
                "# Generate the training dataset.\n",
                "dataset = torch.utils.data.DataLoader(\n",
                "    dataset=torch.utils.data.TensorDataset(x, y),\n",
                "    batch_size=32,\n",
                "    shuffle=True,\n",
                ")\n",
                "\n",
                "\n",
                "# Create the model\n",
                "model = InceptionModel(input_size=x.shape[1], num_classes=3, filters=32, depth=6).to(\n",
                "    device\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = Model(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training model on mps.\n"
                    ]
                },
                {
                    "ename": "TypeError",
                    "evalue": "Model.forward() missing 1 required positional argument: 'x_mark_enc'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[29], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m features, target \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m     12\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 13\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(output, target\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     15\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
                        "File \u001b[0;32m~/miniforge3/envs/pain/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/miniforge3/envs/pain/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "\u001b[0;31mTypeError\u001b[0m: Model.forward() missing 1 required positional argument: 'x_mark_enc'"
                    ]
                }
            ],
            "source": [
                "# Define the optimizer.\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
                "\n",
                "# Define the loss function.\n",
                "loss_fn = torch.nn.CrossEntropyLoss()\n",
                "\n",
                "# Train the model.\n",
                "print(f\"Training model on {device}.\")\n",
                "model.train(True)\n",
                "for epoch in range(20):\n",
                "    for features, target in dataset:\n",
                "        optimizer.zero_grad()\n",
                "        output = model(features.to(device))\n",
                "        loss = loss_fn(output, target.to(device))\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        accuracy = (\n",
                "            torch.argmax(torch.nn.functional.softmax(output, dim=-1), dim=-1) == target\n",
                "        ).float().sum() / target.shape[0]\n",
                "        print(\n",
                "            \"epoch: {}, loss: {:,.6f}, accuracy: {:.6f}\".format(\n",
                "                1 + epoch, loss, accuracy\n",
                "            )\n",
                "        )\n",
                "model.train(False)\n",
                "print(\"-----------------------------------------\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.fft\n",
                "import torch.nn.functional as F\n",
                "from layers.Conv_Blocks import Inception_Block_V1\n",
                "from layers.Embed import DataEmbedding\n",
                "\n",
                "\n",
                "def FFT_for_Period(x, k=2):\n",
                "    # [B, T, C]\n",
                "    xf = torch.fft.rfft(x, dim=1)\n",
                "    # find period by amplitudes\n",
                "    frequency_list = abs(xf).mean(0).mean(-1)\n",
                "    frequency_list[0] = 0\n",
                "    _, top_list = torch.topk(frequency_list, k)\n",
                "    top_list = top_list.detach().cpu().numpy()\n",
                "    period = x.shape[1] // top_list\n",
                "    return period, abs(xf).mean(-1)[:, top_list]\n",
                "\n",
                "\n",
                "class TimesBlock(nn.Module):\n",
                "    def __init__(\n",
                "        # TODO: NOTE random default values! compare with\n",
                "        self,\n",
                "        seq_len,\n",
                "        d_model=512,\n",
                "        d_ff=2048,\n",
                "        num_kernels=32,\n",
                "        top_k=2,\n",
                "    ):\n",
                "        super(TimesBlock, self).__init__()\n",
                "        self.seq_len = seq_len\n",
                "        self.k = top_k\n",
                "        # parameter-efficient design\n",
                "        self.conv = nn.Sequential(\n",
                "            Inception_Block_V1(d_model, d_ff, num_kernels=num_kernels),\n",
                "            nn.GELU(),\n",
                "            Inception_Block_V1(d_ff, d_model, num_kernels=num_kernels),\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        B, T, N = x.size()\n",
                "        period_list, period_weight = FFT_for_Period(x, self.k)\n",
                "\n",
                "        res = []\n",
                "        for i in range(self.k):\n",
                "            period = period_list[i]\n",
                "            # padding\n",
                "            if (self.seq_len) % period != 0:\n",
                "                length = (((self.seq_len) // period) + 1) * period\n",
                "                padding = torch.zeros(\n",
                "                    [x.shape[0], (length - (self.seq_len)), x.shape[2]]\n",
                "                ).to(x.device)\n",
                "                out = torch.cat([x, padding], dim=1)\n",
                "            else:\n",
                "                length = self.seq_len\n",
                "                out = x\n",
                "            # reshape\n",
                "            out = (\n",
                "                out.reshape(B, length // period, period, N)\n",
                "                .permute(0, 3, 1, 2)\n",
                "                .contiguous()\n",
                "            )\n",
                "            # 2D conv: from 1d Variation to 2d Variation\n",
                "            out = self.conv(out)\n",
                "            # reshape back\n",
                "            out = out.permute(0, 2, 3, 1).reshape(B, -1, N)\n",
                "            res.append(out[:, : (self.seq_len), :])\n",
                "        res = torch.stack(res, dim=-1)\n",
                "        # adaptive aggregation\n",
                "        period_weight = F.softmax(period_weight, dim=1)\n",
                "        period_weight = period_weight.unsqueeze(1).unsqueeze(1).repeat(1, T, N, 1)\n",
                "        res = torch.sum(res * period_weight, -1)\n",
                "        # residual connection\n",
                "        res = res + x\n",
                "        return res\n",
                "\n",
                "\n",
                "class Model(nn.Module):\n",
                "    \"\"\"\n",
                "    Paper link: https://openreview.net/pdf?id=ju_Uqw384Oq\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(self, configs):\n",
                "        super(Model, self).__init__()\n",
                "        self.configs = configs\n",
                "        self.seq_len = configs.seq_len\n",
                "        self.label_len = configs.label_len\n",
                "        self.model = nn.ModuleList(\n",
                "            [TimesBlock(configs) for _ in range(configs.e_layers)]\n",
                "        )\n",
                "        self.enc_embedding = DataEmbedding(\n",
                "            configs.enc_in,\n",
                "            configs.d_model,\n",
                "            configs.embed,\n",
                "            configs.freq,\n",
                "            configs.dropout,\n",
                "        )\n",
                "        self.layer = configs.e_layers\n",
                "        self.layer_norm = nn.LayerNorm(configs.d_model)\n",
                "\n",
                "        # Classification\n",
                "        self.act = F.gelu\n",
                "        self.dropout = nn.Dropout(configs.dropout)\n",
                "        self.projection = nn.Linear(\n",
                "            configs.d_model * configs.seq_len, configs.num_class\n",
                "        )\n",
                "\n",
                "    def classification(self, x_enc, x_mark_enc):\n",
                "        # embedding\n",
                "        enc_out = self.enc_embedding(x_enc, None)  # [B,T,C]\n",
                "        # TimesNet\n",
                "        for i in range(self.layer):\n",
                "            enc_out = self.layer_norm(self.model[i](enc_out))\n",
                "\n",
                "        # Output\n",
                "        # the output transformer encoder/decoder embeddings don't include non-linearity\n",
                "        output = self.act(enc_out)\n",
                "        output = self.dropout(output)\n",
                "        # zero-out padding embeddings\n",
                "        output = output * x_mark_enc.unsqueeze(-1)\n",
                "        # (batch_size, seq_length * d_model)\n",
                "        output = output.reshape(output.shape[0], -1)\n",
                "        output = self.projection(output)  # (batch_size, num_classes)\n",
                "        return output\n",
                "\n",
                "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask=None):\n",
                "        dec_out = self.classification(x_enc, x_mark_enc)\n",
                "        return dec_out  # [B, N]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 125,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "inf"
                        ]
                    },
                    "execution_count": 125,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "np.inf"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "ic| a: {'a': 1, 'b': 2, 'c': 3}\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'a': 1, 'b': 2, 'c': 3}"
                        ]
                    },
                    "execution_count": 162,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "a = dict(a=1, b=2, c=3)\n",
                "\n",
                "\n",
                "ic(a)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 161,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor(-0.4004)\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(tensor([[42.0000, 42.0000],\n",
                            "         [ 0.0539, -0.4846],\n",
                            "         [ 0.5358, -0.3474]]),\n",
                            " tensor([[-0.4004,  0.0539,  0.5358],\n",
                            "         [ 0.7502, -0.4846, -0.3474]]))"
                        ]
                    },
                    "execution_count": 161,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "x = torch.randn(3, 2)\n",
                "y = torch.transpose(x, 0, 1).contiguous()\n",
                "x[0, :] = 42\n",
                "print(y.contiguous()[0, 0])\n",
                "x, y"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div><style>\n",
                            ".dataframe > thead > tr,\n",
                            ".dataframe > tbody > tr {\n",
                            "  text-align: right;\n",
                            "  white-space: pre-wrap;\n",
                            "}\n",
                            "</style>\n",
                            "<small>shape: (848_271, 33)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>trial_id</th><th>trial_number</th><th>participant_id</th><th>timestamp</th><th>temperature</th><th>rating</th><th>eda_raw</th><th>eda_tonic</th><th>eda_phasic</th><th>ppg_raw</th><th>ppg_ibi_shimmer</th><th>heartrate</th><th>pupil_l_raw</th><th>pupil_r_raw</th><th>pupil_r</th><th>pupil_l</th><th>pupil_mean</th><th>pupil_mean_tonic</th><th>brow_furrow</th><th>cheek_raise</th><th>mouth_open</th><th>upper_lip_raise</th><th>nose_wrinkle</th><th>normalized_timestamp</th><th>stimulus_seed</th><th>skin_patch</th><th>decreasing_intervals</th><th>major_decreasing_intervals</th><th>increasing_intervals</th><th>strictly_increasing_intervals</th><th>strictly_increasing_intervals_without_plateaus</th><th>plateau_intervals</th><th>prolonged_minima_intervals</th></tr><tr><td>u16</td><td>u8</td><td>u8</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>u16</td><td>u8</td><td>u16</td><td>u16</td><td>u16</td><td>u16</td><td>u16</td><td>u16</td><td>u16</td></tr></thead><tbody><tr><td>1</td><td>1</td><td>1</td><td>294198.9762</td><td>0.0</td><td>0.425</td><td>0.743774</td><td>0.743503</td><td>0.000271</td><td>1408.404382</td><td>-1.062977</td><td>65.243881</td><td>5.670313</td><td>6.173421</td><td>5.641376</td><td>5.15944</td><td>5.400408</td><td>5.350094</td><td>0.00036</td><td>0.00286</td><td>0.0048</td><td>0.0</td><td>0.00007</td><td>0.0</td><td>396</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>1</td><td>1</td><td>1</td><td>294298.9762</td><td>0.000039</td><td>0.425</td><td>0.744641</td><td>0.743517</td><td>0.001124</td><td>1372.864366</td><td>-0.131651</td><td>65.242949</td><td>5.602895</td><td>6.142564</td><td>5.639922</td><td>5.157792</td><td>5.398857</td><td>5.343983</td><td>0.00036</td><td>0.00286</td><td>0.0048</td><td>0.0</td><td>0.00007</td><td>100.0</td><td>396</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>1</td><td>1</td><td>1</td><td>294398.9762</td><td>0.000154</td><td>0.395798</td><td>0.74488</td><td>0.743537</td><td>0.001343</td><td>1397.15563</td><td>-2.948082</td><td>65.241069</td><td>5.518026</td><td>6.072123</td><td>5.643301</td><td>5.160338</td><td>5.401819</td><td>5.337462</td><td>0.000341</td><td>0.002327</td><td>0.004199</td><td>0.0</td><td>0.000065</td><td>200.0</td><td>396</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>1</td><td>1</td><td>1</td><td>294498.9762</td><td>0.000417</td><td>0.270286</td><td>0.744808</td><td>0.743557</td><td>0.001252</td><td>1485.360361</td><td>1.488009</td><td>65.238629</td><td>5.399583</td><td>5.947853</td><td>5.638149</td><td>5.156922</td><td>5.397535</td><td>5.330919</td><td>0.000512</td><td>0.00122</td><td>0.002504</td><td>0.0</td><td>0.000065</td><td>300.0</td><td>396</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>1</td><td>1</td><td>1</td><td>294598.9762</td><td>0.000818</td><td>0.129521</td><td>0.74487</td><td>0.743578</td><td>0.001293</td><td>1496.64849</td><td>-4.735116</td><td>65.235505</td><td>5.276378</td><td>5.796069</td><td>5.646014</td><td>5.1618</td><td>5.403907</td><td>5.324177</td><td>0.001059</td><td>0.000701</td><td>0.002202</td><td>0.000006</td><td>0.000093</td><td>400.0</td><td>396</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>1</td><td>1</td><td>1</td><td>294698.9762</td><td>0.001358</td><td>0.152477</td><td>0.744957</td><td>0.743594</td><td>0.001363</td><td>1456.946658</td><td>1.28125</td><td>65.233139</td><td>5.158002</td><td>5.642459</td><td>5.62452</td><td>5.146081</td><td>5.3853</td><td>5.317484</td><td>0.001138</td><td>0.000565</td><td>0.001937</td><td>0.000017</td><td>0.00009</td><td>500.0</td><td>396</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>516</td><td>12</td><td>50</td><td>2.6956e6</td><td>0.031312</td><td>0.0</td><td>26.688608</td><td>26.716225</td><td>0.003169</td><td>1323.813266</td><td>-5.036073</td><td>59.279672</td><td>5.166699</td><td>4.766597</td><td>4.768156</td><td>5.167254</td><td>4.967705</td><td>5.180142</td><td>0.000465</td><td>0.001124</td><td>0.007081</td><td>0.00022</td><td>0.004168</td><td>179500.0</td><td>806</td><td>1</td><td>2580</td><td>1548</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>516</td><td>12</td><td>50</td><td>2.6957e6</td><td>0.030874</td><td>0.0</td><td>26.68499</td><td>26.716212</td><td>0.000389</td><td>1244.871959</td><td>44.337204</td><td>58.673362</td><td>5.026438</td><td>4.683481</td><td>4.690238</td><td>5.025632</td><td>4.857935</td><td>5.174284</td><td>0.000698</td><td>0.000846</td><td>0.007044</td><td>0.000348</td><td>0.004289</td><td>179600.0</td><td>806</td><td>1</td><td>2580</td><td>1548</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>516</td><td>12</td><td>50</td><td>2.6958e6</td><td>0.030555</td><td>0.0</td><td>26.683944</td><td>26.716204</td><td>0.000132</td><td>1223.099413</td><td>55.805969</td><td>58.073701</td><td>4.929092</td><td>4.633568</td><td>4.655852</td><td>4.930955</td><td>4.793404</td><td>5.169684</td><td>0.001266</td><td>0.000706</td><td>0.011259</td><td>0.000379</td><td>0.006841</td><td>179700.0</td><td>806</td><td>1</td><td>2580</td><td>1548</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>516</td><td>12</td><td>50</td><td>2.6959e6</td><td>0.030355</td><td>0.0</td><td>26.67662</td><td>26.716199</td><td>-0.006472</td><td>1209.194684</td><td>3.987454</td><td>57.589289</td><td>4.892469</td><td>4.615016</td><td>4.639233</td><td>4.892883</td><td>4.766058</td><td>5.166363</td><td>0.000538</td><td>0.000713</td><td>0.007119</td><td>0.000194</td><td>0.004404</td><td>179800.0</td><td>806</td><td>1</td><td>2580</td><td>1548</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>516</td><td>12</td><td>50</td><td>2.6960e6</td><td>0.030266</td><td>0.0</td><td>26.673635</td><td>26.716196</td><td>-0.008718</td><td>1185.269861</td><td>-8.486648</td><td>57.260022</td><td>4.884521</td><td>4.629964</td><td>4.622166</td><td>4.886672</td><td>4.754419</td><td>5.164178</td><td>0.000372</td><td>0.00049</td><td>0.006667</td><td>0.000138</td><td>0.003204</td><td>179900.0</td><td>806</td><td>1</td><td>2580</td><td>1548</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>516</td><td>12</td><td>50</td><td>2.6961e6</td><td>0.030251</td><td>0.0</td><td>26.676667</td><td>26.716195</td><td>-0.005103</td><td>1176.373587</td><td>8.110077</td><td>57.105773</td><td>4.882422</td><td>4.648883</td><td>4.610538</td><td>4.884064</td><td>4.747301</td><td>5.16335</td><td>0.000121</td><td>0.00074</td><td>0.015191</td><td>0.000349</td><td>0.001363</td><td>180000.0</td><td>806</td><td>1</td><td>2580</td><td>1548</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
                        ],
                        "text/plain": [
                            "shape: (848_271, 33)\n",
                            "\n",
                            " trial_id  trial_num  participa  timestamp    strictly_  strictly_  plateau_i  prolonged \n",
                            " ---       ber        nt_id      ---           increasin  increasin  ntervals   _minima_i \n",
                            " u16       ---        ---        f64           g_interva  g_interva  ---        ntervals  \n",
                            "           u8         u8                       ls         ls_       u16        ---       \n",
                            "                                               ---        ---                   u16       \n",
                            "                                               u16        u16                             \n",
                            "\n",
                            " 1         1          1          294198.97    0          0          0          0         \n",
                            "                                 62                                                       \n",
                            " 1         1          1          294298.97    0          0          0          0         \n",
                            "                                 62                                                       \n",
                            " 1         1          1          294398.97    0          0          0          0         \n",
                            "                                 62                                                       \n",
                            " 1         1          1          294498.97    0          0          0          0         \n",
                            "                                 62                                                       \n",
                            " 1         1          1          294598.97    0          0          0          0         \n",
                            "                                 62                                                       \n",
                            " 1         1          1          294698.97    0          0          0          0         \n",
                            "                                 62                                                       \n",
                            "                                                                                 \n",
                            " 516       12         50         2.6956e6     0          0          0          0         \n",
                            " 516       12         50         2.6957e6     0          0          0          0         \n",
                            " 516       12         50         2.6958e6     0          0          0          0         \n",
                            " 516       12         50         2.6959e6     0          0          0          0         \n",
                            " 516       12         50         2.6960e6     0          0          0          0         \n",
                            " 516       12         50         2.6961e6     0          0          0          0         \n",
                            ""
                        ]
                    },
                    "execution_count": 41,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "db = DatabaseManager()\n",
                "\n",
                "with db:\n",
                "    df = db.get_table(\n",
                "        \"Merged_and_Labeled_Data\",\n",
                "        exclude_trials_with_measurement_problems=True,\n",
                "    )\n",
                "    trials = db.get_table(\"Trials\", exclude_trials_with_measurement_problems=True)\n",
                "df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "# prepare_multiline_hvplot(\n",
                "#     add_normalized_timestamp(df, \"timestamp\", \"major_decreasing_intervals\"),\n",
                "#     \"normalized_timestamp\",\n",
                "#     \"major_decreasing_intervals\",\n",
                "# ).filter(col(\"major_decreasing_intervals\") > 0).hvplot(\n",
                "#     x=\"normalized_timestamp\", y=\"temperature\"\n",
                "# )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "shape: (2, 2)\n",
                        "\n",
                        " label  count \n",
                        " ---    ---   \n",
                        " u8     u32   \n",
                        "\n",
                        " 0      72063 \n",
                        " 1      72063 \n",
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div><style>\n",
                            ".dataframe > thead > tr,\n",
                            ".dataframe > tbody > tr {\n",
                            "  text-align: right;\n",
                            "  white-space: pre-wrap;\n",
                            "}\n",
                            "</style>\n",
                            "<small>shape: (144_126, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sample_id</th><th>participant_id</th><th>timestamp</th><th>temperature</th><th>eda_raw</th><th>eda_tonic</th><th>eda_phasic</th><th>pupil_mean</th><th>pupil_mean_tonic</th><th>label</th></tr><tr><td>u16</td><td>u8</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>u8</td></tr></thead><tbody><tr><td>1</td><td>1</td><td>363198.9762</td><td>0.967948</td><td>0.744613</td><td>0.744586</td><td>0.000027</td><td>4.658733</td><td>4.709513</td><td>0</td></tr><tr><td>1</td><td>1</td><td>363298.9762</td><td>0.967909</td><td>0.744724</td><td>0.744573</td><td>0.000151</td><td>4.659884</td><td>4.688126</td><td>0</td></tr><tr><td>1</td><td>1</td><td>363398.9762</td><td>0.967773</td><td>0.74465</td><td>0.74456</td><td>0.00009</td><td>4.658591</td><td>4.666663</td><td>0</td></tr><tr><td>1</td><td>1</td><td>363498.9762</td><td>0.967524</td><td>0.744585</td><td>0.744545</td><td>0.00004</td><td>4.637682</td><td>4.645174</td><td>0</td></tr><tr><td>1</td><td>1</td><td>363598.9762</td><td>0.967158</td><td>0.74454</td><td>0.744529</td><td>0.000011</td><td>4.581029</td><td>4.62372</td><td>0</td></tr><tr><td>1</td><td>1</td><td>363698.9762</td><td>0.966678</td><td>0.744388</td><td>0.744515</td><td>-0.000127</td><td>4.556353</td><td>4.602361</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>3096</td><td>50</td><td>2.6176e6</td><td>0.566078</td><td>28.028736</td><td>27.657549</td><td>0.371187</td><td>5.555003</td><td>5.493403</td><td>1</td></tr><tr><td>3096</td><td>50</td><td>2.6177e6</td><td>0.581691</td><td>28.044775</td><td>27.66556</td><td>0.379215</td><td>5.563552</td><td>5.496715</td><td>1</td></tr><tr><td>3096</td><td>50</td><td>2.6178e6</td><td>0.597184</td><td>28.058645</td><td>27.673215</td><td>0.38543</td><td>5.563949</td><td>5.499627</td><td>1</td></tr><tr><td>3096</td><td>50</td><td>2.6179e6</td><td>0.612597</td><td>28.062966</td><td>27.681188</td><td>0.381778</td><td>5.558605</td><td>5.502192</td><td>1</td></tr><tr><td>3096</td><td>50</td><td>2.6180e6</td><td>0.627982</td><td>28.066265</td><td>27.688689</td><td>0.377576</td><td>5.548888</td><td>5.504481</td><td>1</td></tr><tr><td>3096</td><td>50</td><td>2.6181e6</td><td>0.643138</td><td>28.075839</td><td>27.695924</td><td>0.379915</td><td>5.540484</td><td>5.506575</td><td>1</td></tr></tbody></table></div>"
                        ],
                        "text/plain": [
                            "shape: (144_126, 10)\n",
                            "\n",
                            " sample_id  participan  timestamp   temperatur    eda_phasi  pupil_mea  pupil_mea  label \n",
                            " ---        t_id        ---         e              c          n          n_tonic    ---   \n",
                            " u16        ---         f64         ---            ---        ---        ---        u8    \n",
                            "            u8                      f64            f64        f64        f64              \n",
                            "\n",
                            " 1          1           363198.976  0.967948      0.000027   4.658733   4.709513   0     \n",
                            "                        2                                                                 \n",
                            " 1          1           363298.976  0.967909      0.000151   4.659884   4.688126   0     \n",
                            "                        2                                                                 \n",
                            " 1          1           363398.976  0.967773      0.00009    4.658591   4.666663   0     \n",
                            "                        2                                                                 \n",
                            " 1          1           363498.976  0.967524      0.00004    4.637682   4.645174   0     \n",
                            "                        2                                                                 \n",
                            " 1          1           363598.976  0.967158      0.000011   4.581029   4.62372    0     \n",
                            "                        2                                                                 \n",
                            " 1          1           363698.976  0.966678      -0.000127  4.556353   4.602361   0     \n",
                            "                        2                                                                 \n",
                            "                                                                                 \n",
                            " 3096       50          2.6176e6    0.566078      0.371187   5.555003   5.493403   1     \n",
                            " 3096       50          2.6177e6    0.581691      0.379215   5.563552   5.496715   1     \n",
                            " 3096       50          2.6178e6    0.597184      0.38543    5.563949   5.499627   1     \n",
                            " 3096       50          2.6179e6    0.612597      0.381778   5.558605   5.502192   1     \n",
                            " 3096       50          2.6180e6    0.627982      0.377576   5.548888   5.504481   1     \n",
                            " 3096       50          2.6181e6    0.643138      0.379915   5.540484   5.506575   1     \n",
                            ""
                        ]
                    },
                    "execution_count": 42,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "intervals = {\n",
                "    # \"decreases\": \"decreasing_intervals\",\n",
                "    \"decreases\": \"major_decreasing_intervals\",\n",
                "    \"increases\": \"strictly_increasing_intervals_without_plateaus\",\n",
                "    # \"plateaus\": \"plateau_intervals\",\n",
                "}\n",
                "label_mapping = {\n",
                "    \"decreases\": 0,\n",
                "    \"increases\": 1,\n",
                "    # \"plateaus\": 1,\n",
                "}\n",
                "sample_duration_ms = 5_000\n",
                "\n",
                "samples = create_samples(df, intervals, sample_duration_ms, label_mapping)\n",
                "samples = make_sample_set_balanced(\n",
                "    samples\n",
                ")  # TODO: improve balance function, maybe use f1 or mcc as metric instead of accuracy\n",
                "samples = samples.select(\n",
                "    \"sample_id\",\n",
                "    \"participant_id\",\n",
                "    \"timestamp\",\n",
                "    \"temperature\",\n",
                "    \"eda_raw\",\n",
                "    \"eda_tonic\",\n",
                "    \"eda_phasic\",\n",
                "    \"pupil_mean\",\n",
                "    \"pupil_mean_tonic\",\n",
                "    \"label\",\n",
                ")\n",
                "print(samples[\"label\"].value_counts())\n",
                "samples\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "X.shape=(2826, 51, 3), y.shape=(2826, 2), groups.shape=(2826,)\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "abb6b309c50f42a9b8b55d4b6c4a3e80",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "interactive(children=(IntSlider(value=1412, description='trial', max=2825), Output()), _dom_classes=('widget-i"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "X, y, groups = transform_sample_df_to_arrays(\n",
                "    samples,\n",
                "    feature_columns=[\n",
                "        # \"temperature\",  # only for visualization\n",
                "        # \"rating\"\n",
                "        \"eda_raw\",\n",
                "        \"eda_tonic\",\n",
                "        \"pupil_mean\",\n",
                "    ],\n",
                ")\n",
                "print(f\"{X.shape=}, {y.shape=}, {groups.shape=}\")\n",
                "\n",
                "\n",
                "@interact(trial=(0, X.shape[0] - 1))\n",
                "def plot_trial(trial):\n",
                "    for i in range(X.shape[2]):\n",
                "        plt.plot(X[trial, :, i])\n",
                "    # plt.ylim(0, 1.05)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c07d028de80342a0bb2c7519aab708e6",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "interactive(children=(IntSlider(value=698, description='trial', max=1397), Output()), _dom_classes=('widget-in"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Create a single train-test split while respecting group structure in the data\n",
                "splitter = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
                "# might not be exactly 50% due to group structure\n",
                "train_idx, test_idx = next(splitter.split(X, y, groups=groups))\n",
                "assert set(groups[train_idx]).isdisjoint(set(groups[test_idx])), \"Overlap in groups\"\n",
                "X_train, y_train = X[train_idx], y[train_idx]\n",
                "X_test, y_test = X[test_idx], y[test_idx]\n",
                "\n",
                "\n",
                "X_train, X_test = scale_dataset(X_train, X_test)\n",
                "\n",
                "\n",
                "@interact(trial=(0, X_train.shape[0] - 1))\n",
                "def plot_trial(trial):\n",
                "    for i in range(X.shape[2]):\n",
                "        plt.plot(X_train[trial, :, i])\n",
                "    # plt.ylim(0, 1.05)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "18:34:22 | \u001b[36mDEBUG   \u001b[0m| data_loader | Dataset summary: Train: 1398 samples, Test: 1428 samples | Input shape: (1398, 51, 3), Label shape: (1398, 2)\n"
                    ]
                }
            ],
            "source": [
                "batch_size = 64\n",
                "\n",
                "train_loader, test_loader = create_dataloaders(\n",
                "    X_train,\n",
                "    y_train,\n",
                "    X_test,\n",
                "    y_test,\n",
                "    batch_size=batch_size,\n",
                "    is_test=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(64, 51, 3)"
                        ]
                    },
                    "execution_count": 48,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "next(iter(train_loader))[0].numpy().shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {},
            "outputs": [],
            "source": [
                "MODELS = {\n",
                "    \"MLP\": {\n",
                "        \"class\": MultiLayerPerceptron,\n",
                "        \"format\": \"2D\",\n",
                "        \"hyperparameters\": {\n",
                "            \"hidden_size\": {\"type\": \"int\", \"low\": 128, \"high\": 4096},\n",
                "            \"lr\": {\"type\": \"float\", \"low\": 1e-5, \"high\": 1e-1, \"log\": True},\n",
                "        },\n",
                "    },\n",
                "    # Define other models with their respective hyperparameters and input sizes\n",
                "    # \"LSTM\": {\n",
                "    #     \"class\": LongShortTermMemory,\n",
                "    #     \"format\": \"3D\",\n",
                "    #     \"hyperparameters\": {\n",
                "    #         \"hidden_size\": {\"type\": \"int\", \"low\": 128, \"high\": 1024},\n",
                "    #         \"num_layers\": {\"type\": \"int\", \"low\": 1, \"high\": 2},\n",
                "    #         \"lr\": {\"type\": \"float\", \"low\": 1e-5, \"high\": 1e-1, \"log\": True},\n",
                "    #     },\n",
                "    # },\n",
                "    # \"InceptionTime\": {\n",
                "    #     \"class\": Inception,\n",
                "    #     \"format\": \"3D\",\n",
                "    #     \"hyperparameters\": {\n",
                "    #         \"n_filters\": {\"type\": \"int\", \"low\": 32, \"high\": 256},\n",
                "}\n",
                "\n",
                "\n",
                "def get_input_size(\n",
                "    model_name: str,\n",
                "    X: np.ndarray | DataLoader,\n",
                "):\n",
                "    data_format = MODELS[model_name][\"format\"]\n",
                "    if isinstance(X, DataLoader):\n",
                "        X = next(iter(X))[0].numpy()\n",
                "    match data_format:\n",
                "        case \"2D\":\n",
                "            return X.shape[2] * X.shape[1]\n",
                "        case \"3D\":\n",
                "            return X.shape[2]\n",
                "        case _:\n",
                "            raise ValueError(f\"Unknown data format: {data_format}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_model(\n",
                "    model: nn.Module,\n",
                "    train_loader: DataLoader,\n",
                "    test_loader: DataLoader,\n",
                "    criterion: nn.modules.loss._Loss,\n",
                "    optimizer: optim.Optimizer,\n",
                "    epochs: int,\n",
                "    is_test: bool = True,\n",
                ") -> dict[str, list[float]]:\n",
                "    dataset = \"test\" if is_test else \"validation\"\n",
                "    history = {\n",
                "        \"train_accuracy\": [],\n",
                "        \"train_loss\": [],\n",
                "        f\"{dataset}_accuracy\": [],\n",
                "        f\"{dataset}_loss\": [],\n",
                "    }\n",
                "\n",
                "    for epoch in range(epochs):\n",
                "        model.train()\n",
                "        running_loss = 0.0\n",
                "        # for acc metric only\n",
                "        correct = 0\n",
                "        total = 0\n",
                "        for X_batch, y_batch in train_loader:\n",
                "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
                "            optimizer.zero_grad()\n",
                "            outputs = model(X_batch)\n",
                "            loss = criterion(outputs, y_batch)\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "            running_loss += loss.item() * X_batch.size(0)\n",
                "\n",
                "            # Calculate training accuracy\n",
                "            y_pred_classes = (torch.sigmoid(outputs) >= 0.5).float()\n",
                "            total += y_batch.size(0)\n",
                "            correct += (y_pred_classes == y_batch).sum().item()\n",
                "\n",
                "        epoch_loss = running_loss / len(train_loader.dataset)\n",
                "        epoch_acc = correct / total if total > 0 else 0\n",
                "        test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
                "\n",
                "        # Store the metrics in the history dictionary\n",
                "        history[\"train_loss\"].append(epoch_loss)\n",
                "        history[\"train_accuracy\"].append(epoch_acc)\n",
                "        history[f\"{dataset}_loss\"].append(test_loss)\n",
                "        history[f\"{dataset}_accuracy\"].append(test_accuracy)\n",
                "\n",
                "        # Log progress\n",
                "        max_digits = len(str(epochs))\n",
                "        logging.debug(\n",
                "            f\"E[{+epoch + 1:>{max_digits}d}/{epochs}] \"\n",
                "            f\"| train {epoch_loss:.4f} ({epoch_acc:.1%}) \"\n",
                "            f\" {dataset} {test_loss:.4f} ({test_accuracy:.1%})\"\n",
                "        )\n",
                "\n",
                "    return history\n",
                "\n",
                "\n",
                "def evaluate_model(\n",
                "    model: nn.Module,\n",
                "    test_loader: DataLoader,\n",
                "    criterion: nn.modules.loss._Loss,\n",
                ") -> tuple[float, float]:\n",
                "    model.eval()\n",
                "    total_loss = 0.0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    with torch.inference_mode():\n",
                "        for X_batch, y_batch in test_loader:\n",
                "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
                "            y_pred_logits = model(X_batch)\n",
                "            loss = criterion(y_pred_logits, y_batch)\n",
                "            total_loss += loss.item() * X_batch.size(0)\n",
                "            # Metric here is acc\n",
                "            y_pred_classes = (torch.sigmoid(y_pred_logits) >= 0.5).float()\n",
                "            total += y_batch.size(0)\n",
                "            correct += (y_pred_classes == y_batch).sum().item()\n",
                "\n",
                "    average_loss = total_loss / total if total > 0 else 0\n",
                "    accuracy = correct / total if total > 0 else 0\n",
                "    return average_loss, accuracy\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = LongShortTermMemory(\n",
                "    input_size=X_train.shape[1], hidden_size=256, num_layers=1\n",
                ").to(device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "3"
                        ]
                    },
                    "execution_count": 52,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "X_train.shape[2]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [
                {
                    "ename": "RuntimeError",
                    "evalue": "Given groups=1, weight of size [32, 10, 1], expected input[64, 51, 3] to have 10 channels, but got 51 channels instead",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[53], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n\u001b[0;32m     11\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m---> 14\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m)\u001b[49m\n",
                        "Cell \u001b[1;32mIn[50], line 27\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, test_loader, criterion, optimizer, epochs, is_test)\u001b[0m\n\u001b[0;32m     25\u001b[0m X_batch, y_batch \u001b[38;5;241m=\u001b[39m X_batch\u001b[38;5;241m.\u001b[39mto(device), y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 27\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_batch)\n\u001b[0;32m     29\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
                        "File \u001b[1;32mc:\\Users\\visser\\miniconda3\\envs\\pain\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\visser\\miniconda3\\envs\\pain\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
                        "File \u001b[1;32mc:\\Users\\visser\\Dropbox\\PhD\\Code\\pain-measurement\\src\\models\\inception_time_pytorch\\modules.py:138\u001b[0m, in \u001b[0;36mInceptionModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth):\n\u001b[1;32m--> 138\u001b[0m         y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_submodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minception_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43md\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m d \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    140\u001b[0m             y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_submodule(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresidual_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00md\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)(x, y)\n",
                        "File \u001b[1;32mc:\\Users\\visser\\miniconda3\\envs\\pain\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\visser\\miniconda3\\envs\\pain\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
                        "File \u001b[1;32mc:\\Users\\visser\\Dropbox\\PhD\\Code\\pain-measurement\\src\\models\\inception_time_pytorch\\modules.py:67\u001b[0m, in \u001b[0;36mInception.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 67\u001b[0m     x0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbottleneck1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv10(x0)\n\u001b[0;32m     69\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv20(x0)\n",
                        "File \u001b[1;32mc:\\Users\\visser\\miniconda3\\envs\\pain\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\visser\\miniconda3\\envs\\pain\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
                        "File \u001b[1;32mc:\\Users\\visser\\miniconda3\\envs\\pain\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:375\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\visser\\miniconda3\\envs\\pain\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:370\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[0;32m    360\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    361\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    369\u001b[0m     )\n\u001b[1;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 10, 1], expected input[64, 51, 3] to have 10 channels, but got 51 channels instead"
                    ]
                }
            ],
            "source": [
                "lr = 1e-3\n",
                "epochs = 20\n",
                "model = MultiLayerPerceptron(\n",
                "    input_size=X.shape[2] * X.shape[1],  # 2D input length\n",
                "    hidden_size=2048,\n",
                ").to(device)\n",
                "\n",
                "# Create the model\n",
                "model = InceptionModel(input_size=x.shape[1], num_classes=2, filters=32, depth=6)\n",
                "criterion = nn.BCEWithLogitsLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
                "\n",
                "\n",
                "history = train_model(\n",
                "    model,\n",
                "    train_loader,\n",
                "    test_loader,\n",
                "    criterion,\n",
                "    optimizer,\n",
                "    epochs=epochs,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {},
            "outputs": [
                {
                    "ename": "RuntimeError",
                    "evalue": "Given groups=1, weight of size [32, 10, 1], expected input[1, 51, 3] to have 10 channels, but got 51 channels instead",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\visser\\miniconda3\\envs\\pain\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\visser\\miniconda3\\envs\\pain\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
                        "File \u001b[1;32mc:\\Users\\visser\\Dropbox\\PhD\\Code\\pain-measurement\\src\\models\\inception_time_pytorch\\modules.py:138\u001b[0m, in \u001b[0;36mInceptionModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth):\n\u001b[1;32m--> 138\u001b[0m         y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_submodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minception_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43md\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m d \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    140\u001b[0m             y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_submodule(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresidual_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00md\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)(x, y)\n",
                        "File \u001b[1;32mc:\\Users\\visser\\miniconda3\\envs\\pain\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\visser\\miniconda3\\envs\\pain\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
                        "File \u001b[1;32mc:\\Users\\visser\\Dropbox\\PhD\\Code\\pain-measurement\\src\\models\\inception_time_pytorch\\modules.py:67\u001b[0m, in \u001b[0;36mInception.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 67\u001b[0m     x0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbottleneck1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv10(x0)\n\u001b[0;32m     69\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv20(x0)\n",
                        "File \u001b[1;32mc:\\Users\\visser\\miniconda3\\envs\\pain\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\visser\\miniconda3\\envs\\pain\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
                        "File \u001b[1;32mc:\\Users\\visser\\miniconda3\\envs\\pain\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:375\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\visser\\miniconda3\\envs\\pain\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:370\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[0;32m    360\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    361\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    369\u001b[0m     )\n\u001b[1;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 10, 1], expected input[1, 51, 3] to have 10 channels, but got 51 channels instead"
                    ]
                }
            ],
            "source": [
                "model(torch.from_numpy(X_train[0]).unsqueeze(0).to(device))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "18:23:45 | DEBUG   | root | E[20/20] | train 0.6073 (68.1%)  test 0.6094 (67.7%)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_single_model_history(history):\n",
                "    plt.figure(figsize=(15, 3))\n",
                "\n",
                "    plt.subplot(1, 3, 1)\n",
                "    plt.plot(history[\"train_loss\"], label=\"Training Loss\")\n",
                "    plt.plot(history[\"test_loss\"], label=\"Test Loss\")\n",
                "    plt.xlabel(\"Epoch\")\n",
                "    plt.ylabel(\"Loss\")\n",
                "    plt.legend()\n",
                "\n",
                "    plt.subplot(1, 3, 2)\n",
                "    plt.plot(history[\"train_accuracy\"], label=\"Training Accuracy\")\n",
                "    plt.plot(history[\"test_accuracy\"], label=\"Test Accuracy\")\n",
                "    plt.xlabel(\"Epoch\")\n",
                "    plt.ylabel(\"Accuracy\")\n",
                "    plt.legend()\n",
                "\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "\n",
                "plot_single_model_history(history)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 800x600 with 2 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 800x600 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "def get_confusion_matrix(\n",
                "    model: nn.Module,\n",
                "    test_loader: DataLoader,\n",
                "    threshold: float = 0.5,\n",
                ") -> np.ndarray:\n",
                "    \"\"\"\n",
                "    Calculate confusion matrix for binary classification.\n",
                "    Returns a 2x2 numpy array where:\n",
                "    [0,0] = TN, [0,1] = FP\n",
                "    [1,0] = FN, [1,1] = TP\n",
                "    \"\"\"\n",
                "    model.eval()\n",
                "    y_true = []\n",
                "    y_pred = []\n",
                "\n",
                "    with torch.inference_mode():\n",
                "        for X_batch, y_batch in test_loader:\n",
                "            X_batch = X_batch.to(device)\n",
                "            outputs = model(X_batch)\n",
                "            # y_pred_batch = (torch.sigmoid(outputs) >= threshold).cpu().numpy()\n",
                "            # Convert sigmoid outputs to binary predictions (0 or 1)\n",
                "            y_pred_batch = (outputs.squeeze() >= threshold).int().cpu().numpy()\n",
                "            # Ensure y_batch is also converted to numpy and has the right format\n",
                "            y_batch = y_batch.int().cpu().numpy()\n",
                "\n",
                "            y_true.extend(y_batch)\n",
                "            y_pred.extend(y_pred_batch)\n",
                "\n",
                "    # Convert lists to numpy arrays and ensure they're 1D\n",
                "    y_true = np.array(y_true).flatten()\n",
                "    y_pred = np.array(y_pred).flatten()\n",
                "\n",
                "    return confusion_matrix(y_true, y_pred)\n",
                "\n",
                "\n",
                "def plot_confusion_matrix(conf_matrix: np.ndarray) -> None:\n",
                "    plt.figure(figsize=(8, 6))\n",
                "    sns.heatmap(\n",
                "        conf_matrix,\n",
                "        annot=True,\n",
                "        fmt=\"d\",\n",
                "        cmap=\"Blues\",\n",
                "        xticklabels=[\"Negative\", \"Positive\"],\n",
                "        yticklabels=[\"Negative\", \"Positive\"],\n",
                "    )\n",
                "    plt.title(\"Confusion Matrix\")\n",
                "    plt.ylabel(\"True Label\")\n",
                "    plt.xlabel(\"Predicted Label\")\n",
                "    plt.show()\n",
                "\n",
                "\n",
                "def plot_roc_curve(\n",
                "    model: nn.Module,\n",
                "    test_loader: DataLoader,\n",
                ") -> None:\n",
                "    \"\"\"\n",
                "    Plot ROC curve and calculate AUC score for binary classification.\n",
                "    \"\"\"\n",
                "    model.eval()\n",
                "    y_true = []\n",
                "    y_scores = []\n",
                "\n",
                "    with torch.inference_mode():\n",
                "        for X_batch, y_batch in test_loader:\n",
                "            X_batch = X_batch.to(device)\n",
                "            outputs = model(X_batch)\n",
                "            # Get raw probabilities and convert to CPU numpy\n",
                "            y_scores_batch = torch.sigmoid(outputs).squeeze().cpu().numpy()\n",
                "            # Convert labels to numpy and ensure proper format\n",
                "            y_batch = y_batch.int().cpu().numpy()\n",
                "\n",
                "            y_true.extend(y_batch)\n",
                "            y_scores.extend(y_scores_batch)\n",
                "\n",
                "    # Convert lists to numpy arrays and ensure they're 1D\n",
                "    y_true = np.array(y_true).flatten()\n",
                "    y_scores = np.array(y_scores).flatten()\n",
                "\n",
                "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
                "    auc_score = auc(fpr, tpr)\n",
                "\n",
                "    # Find optimal threshold\n",
                "    optimal_idx = np.argmax(tpr - fpr)\n",
                "    optimal_threshold = thresholds[optimal_idx]\n",
                "\n",
                "    plt.figure(figsize=(8, 6))\n",
                "    plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {auc_score:.3f})\")\n",
                "    plt.plot([0, 1], [0, 1], \"k--\")  # diagonal line\n",
                "\n",
                "    # Add marker for optimal threshold\n",
                "    plt.plot(\n",
                "        fpr[optimal_idx],\n",
                "        tpr[optimal_idx],\n",
                "        \"ro\",\n",
                "        label=f\"Optimal (threshold={optimal_threshold:.2f})\",\n",
                "    )\n",
                "\n",
                "    plt.xlim([0.0, 1.0])\n",
                "    plt.ylim([0.0, 1.05])\n",
                "    plt.xlabel(\"False Positive Rate\")\n",
                "    plt.ylabel(\"True Positive Rate\")\n",
                "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
                "    plt.legend(loc=\"lower right\")\n",
                "    plt.grid(True)\n",
                "    plt.show()\n",
                "\n",
                "\n",
                "conf_matrix = get_confusion_matrix(model, test_loader, threshold=0.5)\n",
                "plot_confusion_matrix(conf_matrix)\n",
                "plot_roc_curve(model, test_loader)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from dataclasses import dataclass\n",
                "\n",
                "\n",
                "# @dataclass\n",
                "# class TimesNetConfig:\n",
                "#     task_name: str = \"classification\"\n",
                "#     is_training: int = 1\n",
                "#     model_id: str = \"Heartbeat\"\n",
                "#     model: str = \"TimesNet\"\n",
                "#     data: str = \"UEA\"\n",
                "#     e_layers: int = 3\n",
                "#     batch_size: int = 16\n",
                "#     d_model: int = 16\n",
                "#     d_ff: int = 32\n",
                "#     top_k: int = 1\n",
                "#     des: str = \"Exp\"\n",
                "#     itr: int = 1\n",
                "#     learning_rate: float = 0.001\n",
                "#     train_epochs: int = 30\n",
                "#     patience: int = 10\n",
                "#     seq_len: int = 50\n",
                "#     label_len: int = 1\n",
                "#     pred_len: int = 1\n",
                "#     num_kernels: int = 32\n",
                "#     enc_in: int = 1\n",
                "#     embed: int = 8\n",
                "#     freq: str = \"H\"\n",
                "#     dropout: float = 0.1\n",
                "#     num_class: int = 2\n",
                "\n",
                "#     def to_args_list(self) -> list:\n",
                "#         \"\"\"Convert config to command line arguments list\"\"\"\n",
                "#         args = []\n",
                "#         for key, value in self.__dict__.items():\n",
                "#             args.extend([f\"--{key}\", str(value)])\n",
                "#         return args\n",
                "\n",
                "\n",
                "# # Example usage:\n",
                "# configs = TimesNetConfig()\n",
                "# configs\n",
                "\n",
                "# from time_series_library.models import TimesNet\n",
                "\n",
                "# model = TimesNet.Model(configs)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
                "from sktime.dists_kernels import FlatDist, ScipyDist\n",
                "\n",
                "eucl_dist = FlatDist(ScipyDist())\n",
                "clf = KNeighborsTimeSeriesClassifier(n_neighbors=3, distance=eucl_dist)\n",
                "clf.fit(X_train, y_train)\n",
                "\n",
                "y_pred = clf.predict(X_test)\n",
                "accuracy_score(y_test, y_pred)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "type(clf)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "isinstance(model, torch.nn.Module)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sktime\n",
                "\n",
                "sktime.classification.distance_based._time_series_neighbors.KNeighborsTimeSeriesClassifier.__mro__"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sktime.transformations.panel.rocket import MiniRocketMultivariate\n",
                "\n",
                "minirocket_multi = MiniRocketMultivariate()\n",
                "# minirocket_multi.fit(X_train)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Path.cwd()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import src.models.inception_time_pytorch.model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "# Generate the data\n",
                "N = 60  # number of time series\n",
                "C = 10  # number of dimensions of each time series\n",
                "L = 100  # number of samples of each time series\n",
                "x = np.zeros((N, C, L))\n",
                "t = np.linspace(0, 1, L)\n",
                "c = np.cos(2 * np.pi * (10 * t - 0.5))\n",
                "s = np.sin(2 * np.pi * (20 * t - 0.5))\n",
                "x[: N // 3] = 20 + 20 * c + 5 * np.random.normal(size=(N // 3, C, L))\n",
                "x[N // 3 : 2 * N // 3] = 20 + 20 * s + 5 * np.random.normal(size=(N // 3, C, L))\n",
                "x[2 * N // 3 :] = 20 + 20 * c + 20 * s + 5 * np.random.normal(size=(N // 3, C, L))\n",
                "y = np.concatenate([0 * np.ones(N // 3), 1 * np.ones(N // 3), 2 * np.ones(N // 3)])\n",
                "\n",
                "# Split the data\n",
                "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.3)\n",
                "\n",
                "# Fit the model\n",
                "model = InceptionTime(\n",
                "    x=x_train,\n",
                "    y=y_train,\n",
                "    filters=32,\n",
                "    depth=6,\n",
                "    models=2,\n",
                ")\n",
                "\n",
                "model.fit(\n",
                "    learning_rate=0.001,\n",
                "    batch_size=64,\n",
                "    epochs=50,\n",
                "    verbose=True,\n",
                ")\n",
                "\n",
                "# Evaluate the model\n",
                "yhat_train = model.predict(x_train)\n",
                "yhat_test = model.predict(x_test)\n",
                "print(\"Training accuracy: {:.6f}\".format(accuracy_score(y_train, yhat_train)))\n",
                "print(\"Test accuracy: {:.6f}\".format(accuracy_score(y_test, yhat_test)))\n",
                "\n",
                "# Plot the results\n",
                "fig = plot(x=x_test, y=yhat_test)\n",
                "fig.write_image(\"results.png\", scale=4, height=900, width=700)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "pain",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
